[{"content":" 一句话概括: Arthas 增强后导致 Java 反射获取方法参数信息失败，方法的参数名列表为空。\n背景 反射获取方法参数 当在AspectJ的切面中，需要获取切面方法的参数名信息时，可以怎么做？\n自 JDK 1.8 之后，开始引入 java.lang.reflect.Parameter 类，用于对参数名称的支持，通过使用“-parameters”编译器标志，开发者在编译时可以保留方法参数的名称信息。\n而 StandardReflectionParameterNameDiscoverer 则是Spring封装的，使用 JDK 8 的反射工具，内省方法参数名的工具类，在 Spring MVC 中有大量使用该类获取参数信息。\nArthas 什么是 Arthas 可以参考 官网介绍 。\n简单来说，作为一个 Java 开发，遇到线上问题时才发现由于 日志不齐全、无法debug 等原因无法定位问题时，怎么办？有Arthas就可以处理了。我们能用Arthas来做什么官网也有介绍：\n问题 表现：消失的参数名列表 为了排查线上某个接口的性能问题，使用 Arthas - trace 命令观察指定接口的调用路径以及相应的耗时时，发现当服务刚启动且未发起请求时，使用trace命令观察接口后，所有该接口的调用都会触发一个异常错误：\njava.lang.NullPointerException: Cannot read the array length because \u0026quot;params\u0026quot; is null\n详细查看报错行代码后发现，接口出入参打印是由一个公共组件封装的能力，这个通用组件内会获取接口方法的参数名信息做一些处理。大概代码参考：\n1 2 3 4 5 6 ParameterNameDiscoverer discoverer = new StandardReflectionParameterNameDiscoverer(); Method method = ((MethodSignature) point.getSignature()).getMethod(); String[] params = paramDiscover.getParameterNames(method); for (int len = 0; len \u0026lt; params.length; len++) { // do something } 此刻心里缓缓冒出一个❓\n为什么这个 params 会为 null 呢？\n分析 反射相关 首先来看下反射获取参数名列表的代码: paramDiscover.getParameterNames(method)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class StandardReflectionParameterNameDiscoverer implements ParameterNameDiscoverer { @Override @Nullable public String[] getParameterNames(Method method) { return getParameterNames(method.getParameters()); } @Override @Nullable public String[] getParameterNames(Constructor\u0026lt;?\u0026gt; ctor) { return getParameterNames(ctor.getParameters()); } @Nullable private String[] getParameterNames(Parameter[] parameters) { String[] parameterNames = new String[parameters.length]; for (int i = 0; i \u0026lt; parameters.length; i++) { Parameter param = parameters[i]; if (!param.isNamePresent()) { return null; } parameterNames[i] = param.getName(); } return parameterNames; } } 从实现代码可以看到，当 Parameter#isNamePresent 返回false时，参数名列表才会是个null，那这个方法是干什么用的呢？\n1 2 3 4 public boolean isNamePresent() { // 当没有真实参数数据，或name为null，则会返回false return executable.hasRealParameterData() \u0026amp;\u0026amp; name != null; } 追踪代码可以看到一个关键类：java.lang.reflect.Executable#privateGetParameters\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 private Parameter[] privateGetParameters() { // Use tmp to avoid multiple writes to a volatile. Parameter[] tmp = parameters; if (tmp == null) { // Otherwise, go to the JVM to get them try { tmp = getParameters0(); } catch(IllegalArgumentException e) { // Rethrow ClassFormatErrors throw new MalformedParametersException(\u0026#34;Invalid constant pool index\u0026#34;); } // If we get back nothing, then synthesize parameters if (tmp == null) { hasRealParameterData = false; tmp = synthesizeAllParams(); } else { hasRealParameterData = true; verifyParameters(tmp); } parameters = tmp; } return tmp; } 这个方法的作用简单来说就是，先尝试从JVM中获取参数列表：\n参数列表依旧为null，则说明无参数数据，标记 hasRealParameterData 为false，并尝试合成参数信息（获取参数数量，并以 arg0,1,2…表示） 参数列表不为null，标记 hasRealParameterData 为true，并校验参数列表 到目前为止基本可以确定，因为从JVM中获取的参数列表是个null，才导致出现的 NullPointException，而获取参数信息时调用的java.lang.reflect.Executable#getParameters0 是一个native方法。\nArthas 相关 由于反射相关的Java代码无法定位为什么从JVM中获取的参数列表是个null，再深入就得去看native实现的C++代码了。这时我突然意识到，可以去看看Arthas的issues是不是有人踩过这个坑，于是我就找到了这个：arthas增强类以后参数名会抹除 #2800。\n按照issue的描述来看，当使用arthas对类进行增强的时候，增强类的方法参数名会丢失，变成arg0这种占位符。\n本地用arthas来手动尝试一把：\n1 2 3 4 5 6 7 8 9 10 11 [arthas@40916]$ ognl \u0026#39;@com.xxx.XxxController@class.getMethods()[0].getParameters()\u0026#39; @Parameter[][ @Parameter[com.xxx.ParamVO request], ] [arthas@40916]$ stack com.xxx.XxxController index -n 5 Press Q or Ctrl+C to abort. Affect(class count: 2 , method count: 2) cost in 167 ms, listenerId: 1 [arthas@40916]$ ognl \u0026#39;@com.xxx.XxxController@class.getMethods()[0].getParameters()\u0026#39; @Parameter[][ @Parameter[com.xxx.ParamVO arg0], ] 尝试结果如下：\n第一次执行 getParameters 方法，能正常获取参数名信息：request。 使用stack命令增强 第二次执行 getParameters 方法，获取到的参数名信息就变成了 arg0 到目前为止基本可以确定，params 为 null 的原因，就是因为Arthas。\n深入 排查一番之后，虽然找到了直接原因，但是随之而来的是更多的问题：\nArthas 增强后为什么反射获取参数列表会失败？ 为什么增强后再获取参数列表，参数名就变成了arg0？ 为什么只有在服务启动后首次访问接口前增强会导致后续接口调用失败？ Arthas 增强导致参数名丢失 首先关注这个issue： arthas增强类以后参数名会抹除 #2800 ，其中有提到JDK有一个bug，其会导致JVM在重新加载class时丢失方法参数信息。如下：JDK-8240908 RetransformClass does not know about MethodParameters attribute\n手动尝试一下，是否符合预期，使用JDK17： 可以看到，在触发 Instrumentation#retransformClasses 重新加载类字节码后，参数名信息丢失了。而 Arthas 的实现就是借助 Java Agent 在字节码层面对类和方法进行修改，达到观测目标的。而最终实现就是通过 java.lang.instrument 相关工具，通过 addTransformer/retransformClasses 来修改并重新加载类字节码。\n看看源码：https://github.com/alibaba/arthas\n类增强命令都会继承 EnhancerCommand，而 EnhancerCommand 都会调用 Enhancer#enhance 方法。Enhancer是Arthas中实现的 ClassFileTransformer，用于对类进行增强，参考代码： 从图片中可以观察到，Enhancer 确实会触发上述 Instrumentation#retransformClasses 方法，因此在增强类后会导致参数名丢失。\n为什么是 arg0？ 知道了参数信息丢失的原因后，下一个问题是，为什么参数名会变成arg0？这个就需要回到 Executable#getParameters 方法来看，当JVM丢失参数信息后，Java的反射代码会怎么处理这种情况，直接看代码吧：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * {@return an array of {@code Parameter} objects representing * all the parameters to the underlying executable represented by * this object} An array of length 0 is returned if the executable * has no parameters. * * \u0026lt;p\u0026gt;The parameters of the underlying executable do not necessarily * have unique names, or names that are legal identifiers in the * Java programming language (JLS {@jls 3.8}). * * @throws MalformedParametersException if the class file contains * a MethodParameters attribute that is improperly formatted. */ public Parameter[] getParameters() { // TODO: This may eventually need to be guarded by security // mechanisms similar to those in Field, Method, etc. // // Need to copy the cached array to prevent users from messing // with it. Since parameters are immutable, we can // shallow-copy. return privateGetParameters().clone(); } getParameters 方法最终会调用 privateGetParameter 来获取参数列表，并返回一个对应结果的浅拷贝。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 private transient volatile Parameter[] parameters; private native Parameter[] getParameters0(); // ... private Parameter[] synthesizeAllParams() { final int realparams = getParameterCount(); final Parameter[] out = new Parameter[realparams]; for (int i = 0; i \u0026lt; realparams; i++) // TODO: is there a way to synthetically derive the // modifiers? Probably not in the general case, since // we\u0026#39;d have no way of knowing about them, but there // may be specific cases. out[i] = new Parameter(\u0026#34;arg\u0026#34; + i, 0, this, i); return out; } private Parameter[] privateGetParameters() { // Use tmp to avoid multiple writes to a volatile. Parameter[] tmp = parameters; if (tmp == null) { // Otherwise, go to the JVM to get them try { tmp = getParameters0(); } catch(IllegalArgumentException e) { // Rethrow ClassFormatErrors throw new MalformedParametersException(\u0026#34;Invalid constant pool index\u0026#34;); } // If we get back nothing, then synthesize parameters if (tmp == null) { hasRealParameterData = false; tmp = synthesizeAllParams(); } else { hasRealParameterData = true; verifyParameters(tmp); } parameters = tmp; } return tmp; } privateGetParameter 会先尝试访问 parameters 成员变量，若该变量为null，则会进行初始化流程，否则直接返回。从这段代码可以看到，初始化参数信息时，会先尝试从JVM获取（getParameters0() 是native方法）参数信息，若JVM获取到的参数信息为空，则会标记 hasRealParameterData 为false，并调用 synthesizeAllParams() 方法，hasRealParameterData 会导致 Parameter#isNamePresent 方法返回false，这也是一开始碰到空指针异常的原因了。\n而另一个 synthesizeAllParams 方法的作用，就是在JVM获取的参数信息为空时，以 arg 为前缀尝试注入参数名信息，这也是为什么增强后参数丢失，看到的参数名是arg0的原因。\nMethod 获取参数名缓存 在尝试复现的过程中我发现，只有在服务启动后首次访问接口前增强会导致后续该接口调用失败，如果已经调用过接口再增强，就不会失败了。\n回顾 privateGetParameters 方法后，这个问题的原因也就自然的浮出水面了！\nMethod 是有一个成员变量来缓存参数信息结果的，如果该成员变量不为空，就不会进行初始化，也就不会再从JVM获取参数信息了。\n总结 从JDK的bug单来看，这个问题在 JDK19+ 才会修复，因此在19之前，涉及到使用了 Instrumentation 增强类的工具，需要谨慎使用。另外，封装组件还是要尽量从代码的角度上避免向上抛Exception，自身问题不能影响业务功能。\nArthas 增强命令 arthas增强类的命令，都继承自 EnhancerCommand 类，可以看到涉及到增强的命令如下：\nmonitor stack tt - TimeTunnel trace watch 参考链接 arthas增强类以后参数名会抹除 #2800 JDK Bug单 arthas增强类参考代码 ","date":"2025-01-15T18:32:10+08:00","permalink":"https://urzz.xyz/p/java-reflection-arthas-conflict-jdk-8240908/","title":"Java Reflection - 谁影响了我？"},{"content":"简介 HPE MicroServer 系列是 HPE ProLiant 推出的面向家庭、小型办公室的微型服务器产品，有着体积小、外观漂亮、噪音低等优点。\n由于购买较早，开箱图找不到嘞，因此详细的外观、服务器的内部结构等信息，可以参考下面的文章：\nHPE MicroServer Gen10 Plus 上手玩 HPE Gen10 Plus 开箱和使用 为了方便描述，后续 HPE Gen10 Plus 简称为 gen10p\n硬件 官方默认配置有两种，主要是 CPU 和内存的区别，低配是 G5420 + 8G ECC，高配是 E2224 + 16G ECC。\n默认配置对于我而言是不太够用的，因此在服务器到手后，就对它进行了一次升级。升级配置需要注意的是，gen10p 的电源是 180W 的外置电源，同时，因为功耗转换有损失，并不能卡死 180W 的功耗来选配置，所以升级后的功耗需要自行算一下。\nCPU 首先是 CPU，CPU 的更换可以直接参考 HPE ProLiant 微服务器 Gen10 Plus 终极定制指南 ，主要是要注意功耗。\n不过我更换的 CPU 是 Intel CC150，不在这个列表里，8 核 16 线程，主频锁在 3.5GHz，没有睿频，TDP 95W。因为没有睿频，主频较低导致表现一般，与 i7-8700K 相比，单核性能低 1/4，多核性能超出 10-15%。性能参考：Intel CC150 处理器现世：性能比肩 i7、功耗低于 i5。由于没有睿频，功耗表现很好，很适合 HomeLab 使用。\n内存 gen10p 的官方产品页表示最大支持内存是 32GB，不过实测下来是可以支持 64GB 的，另外还支持非 ECC 内存，如果不需要 ECC 内存的可以省一笔预算了。\n内存我选择了升到了 64GB，三星 DDR4 32GB ECC x2，iLO 可以看到内存信息，不过也有一些 ECC 内存 iLO 认不出来，影响不大。\n硬盘 gen10p 有 4 个 SATA3 的 3.5 寸硬盘位，内部只有一个 PCIe 3.0 X16 单槽/半高 的接口。这个接口可以选择以下类型的扩展：\n显卡：只能选半高的显卡，而且功耗需要限制在 70W 内 网卡：如果有万兆需求，这里可以选择插一张万兆网卡 NVMe 转接卡：可以扩展 SSD 的存储，同时 gen10p 也支持 PCIe 拆分，但是只支持拆分为两个。如果需要拆分为更多，则需要自带主控芯片的转接卡，比如我选择的自带 ASM2824 主控的转接卡：佳翼 NVMe 阵列卡 PCie 转 M.2 转接卡四盘 SSD ASM2824 主控 带涡轮风扇。 需要注意的是，PCIe 插槽的风道基本等于没有，所以散热的压力也比较大，需要注意这里的温度。\n内部接口，除了上述的硬盘位和PCIe扩展槽意外，主板内部还有一个 USB2.0 的插槽。\n我的选择是，内部usb接口插u盘做系统盘，PCIe扩展4x4的NVMe的转接卡，插满4根SSD。\n最终的存储为：2T NVMe SSD x4。至于 4 个 SATA 硬盘位，目前暂时先空着了。\n总结 gen10p 的硬件升级主要就是上述这些了，升级了 CPU 和内存之后，性能就很可观了，这样也可以省下一部分的 VPS 的支出了。\n不过就我个人而言，选择 gen10p 最大的理由就是体积+静音，支持 iLO，优势太大了。\n其他参考链接：\nHPE ProLiant MicroServer Gen10 Plus Ultimate Customization Guide ","date":"2023-02-01T15:49:36+08:00","permalink":"https://urzz.xyz/p/homelab-hpe-gen10plus-overview/","title":"Homelab - HPE Gen10 Plus 概述"},{"content":"简介 Portainer 是一个轻量级的 Container 可视化管理工具，支持管理 docker, k8s。\n安装 docker 安装 portainer 借助docker，可以快速搭建 portainer。\n这里使用docker-compose来配置服务。(需要替换下列配置中的 domain 为自己需要设置的域名)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 cat \u0026gt; ./docker-compose.yml \u0026lt;\u0026lt;EOF version: \u0026#34;3.6\u0026#34; services: portainer: container_name: portainer_server image: portainer/portainer-ce:2.11.0-alpine restart: always ports: - 9000:9000 volumes: - /var/run/docker.sock:/var/run/docker.sock - /data/portainer/portainer_data:/data networks: - traefik labels: - \u0026#34;traefik.enable=true\u0026#34; - \u0026#34;traefik.docker.network=traefik\u0026#34; - \u0026#34;traefik.http.routers.portainer-web.middlewares=https-redirect@file\u0026#34; - \u0026#34;traefik.http.routers.portainer-web.entrypoints=http\u0026#34; - \u0026#34;traefik.http.routers.portainer-web.rule=Host(`domain`)\u0026#34; - \u0026#34;traefik.http.routers.portainer-web.service=portainer-backend\u0026#34; - \u0026#34;traefik.http.routers.portainer-ssl.middlewares=gzip@file\u0026#34; - \u0026#34;traefik.http.routers.portainer-ssl.entrypoints=https\u0026#34; - \u0026#34;traefik.http.routers.portainer-ssl.tls=true\u0026#34; - \u0026#34;traefik.http.routers.portainer-ssl.tls.certresolver=le\u0026#34; - \u0026#34;traefik.http.routers.portainer-ssl.rule=Host(`domain`)\u0026#34; - \u0026#34;traefik.http.routers.portainer-ssl.service=portainer-backend\u0026#34; - \u0026#34;traefik.http.services.portainer-backend.loadbalancer.server.scheme=http\u0026#34; - \u0026#34;traefik.http.services.portainer-backend.loadbalancer.server.port=9000\u0026#34; logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;10m\u0026#34; networks: traefik: external: true EOF docker-compose up -d 使用配置 服务启动后，访问 http://ip:9000，可以看到初始化页面。\n初始化portainer 选择本地docker环境 初始化完成 docker-compose 部署 portainer 中的 stack 对应docker-compose功能，可以使用 portainer 直接部署docker-compose.yml文件\n新增其他docker环境 portainer 可以通过agent或者docker api等方式来远程访问其他服务器的docker环境。\n总结 本文主要介绍了portainer的作用以及部署方式，通过portainer可以比较方便得管理个人的一些docker环境，而不需要ssh登录服务器来部署相关服务，简化了docker部署的一些操作。\n另外，portainer还支持k8s，支持除了docker api以外的方式来管理docker、k8s环境，感兴趣的可以参考：官方文档 v2.11\n","date":"2022-01-17T16:50:05+08:00","permalink":"https://urzz.xyz/p/portainer-management-ui/","title":"Portainer - Docker 可视化管理工具"},{"content":"简介 MyBatis Plus 是一个MyBatis的增强工具，内置通用mapper，提供了基本的curd操作，简化了MyBatis的开发使用工作。 它提供了一个代码生成器工具，可以根据数据库表来自动生成entity、mapper、mapper xml、service、controller等模块的代码，简化项目的初始化工作。\n本文示例所用版本：\nMyBatis-Plus: 3.4.3.1\nmybatis-plus-generator: 3.5.0\n使用 maven依赖配置 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!-- mybatis-plus gen --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-generator\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.velocity\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;velocity-engine-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 package xyz.urzz.selfpubgservice; import com.baomidou.mybatisplus.generator.AutoGenerator; import com.baomidou.mybatisplus.generator.config.*; import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy; public class MybatisPlusGen { public static final String DB_URL = \u0026#34;jdbc:mysql://${mysql_server}:3306/${db_name}\u0026#34;; public static final String DB_USERNAME = \u0026#34;user\u0026#34;; public static final String DB_PASSWD = \u0026#34;passwd\u0026#34;; public static final String MODULE = \u0026#34;self-pubg-service\u0026#34;; public static final String CODE_GEN_PATH = \u0026#34;/src/main/java\u0026#34;; public static final String CODE_AUTHOR = \u0026#34;urzz\u0026#34;; public static final String PACKAGE_PARENT = \u0026#34;xyz.urzz.self.pubg\u0026#34;; public static final String DB_TABLE_PREFIX = \u0026#34;t_\u0026#34;; public static void main(String[] args) { // db config DataSourceConfig dataSourceConfig = new DataSourceConfig .Builder(DB_URL, DB_USERNAME, DB_PASSWD) .build(); // code gen path config String projectPath = System.getProperty(\u0026#34;user.dir\u0026#34;); GlobalConfig globalConfig = new GlobalConfig.Builder() .outputDir(projectPath + \u0026#34;/\u0026#34; + MODULE + CODE_GEN_PATH) // 生成文件后是否打开目录（文件浏览器） .openDir(false) // 覆盖文件 //.fileOverride() .author(CODE_AUTHOR) .build(); // code gen package config PackageConfig packageConfig = new PackageConfig.Builder() // 包路径 .parent(PACKAGE_PARENT) .build(); // code gen strategy config StrategyConfig strategyConfig = new StrategyConfig.Builder() // table prefix .addTablePrefix(DB_TABLE_PREFIX) .entityBuilder() // table -\u0026gt; entity .naming(NamingStrategy.underline_to_camel) // column -\u0026gt; field .columnNaming(NamingStrategy.underline_to_camel) // entity add lombok .enableLombok() .mapperBuilder() // mapper add column list .enableBaseColumnList() // mapper add column map .enableBaseResultMap() .build(); TemplateConfig templateConfig = new TemplateConfig.Builder() // disable gen controller .disable(TemplateType.CONTROLLER) .build(); AutoGenerator autoGenerator = new AutoGenerator(dataSourceConfig); autoGenerator.global(globalConfig) .strategy(strategyConfig) .template(templateConfig) .packageInfo(packageConfig); autoGenerator.execute(); } } 类生成的相关配置在下列的各个配置类中，示例中只是展示了部分的配置。\nDataSourceConfig 数据库链接配置 PackageConfig 类的包路径等配置 StrategyConfig 生成策略配置 TemplateConfig 模板配置 GlobalConfig 全局配置 mybatis-plus-generator 默认使用velocity作为类生成的模板引擎，出了velocity之外，也提供了freemarker和beetl的实现。generator也支持自定义模板，如需自定义，可以继承 AbstractTemplateEngine，参考 VelocityTemplateEngine 的实现。\n使用生成器，极大的简化了项目的初始化工作，可以无需编写繁琐的entity到mapper到service的这一套代码，还是可以大大提升开发效率的。\n","date":"2021-08-08T23:17:14+08:00","permalink":"https://urzz.xyz/p/mybatis-plus-generator-config/","title":"使用mybatis-plus-generator初始化项目"},{"content":" 先说问题：Traefik 本身是不支持代理静态文件的。原因参考: issue 4240\n为什么 这里简单说一下为什么吧，因为它的设计原则是：Separation of Concerns。所以traefik并没有提供代理以外的功能，而静态文件需要一个静态文件服务器。\n怎么实现静态文件代理 为什么需要静态文件代理？其实主要是为了部署前端项目文件。\ntraefik 反代需要 route + service ，因此需要一个静态文件服务器来提供服务，如果只是个人使用，完全可以使用nginx来做静态文件服务器。\nNginx - .env 文件 1 2 3 4 # 应用名称 SERVICE_NAME=nginx_server # 使用的应用镜像 DOCKER_IMAGE=nginx:1.21.0-alpine Nginx - docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 version: \u0026#39;3.6\u0026#39; services: nginx-server: image: ${DOCKER_IMAGE} container_name: ${SERVICE_NAME} environment: - USER_UID=1000 - USER_GID=1000 networks: - traefik restart: unless-stopped labels: - \u0026#34;traefik.enable=true\u0026#34; - \u0026#34;traefik.docker.network=traefik\u0026#34; - \u0026#34;traefik.http.services.nginxserverhttp.loadbalancer.server.scheme=http\u0026#34; - \u0026#34;traefik.http.services.nginxserverhttp.loadbalancer.server.port=80\u0026#34; volumes: - /etc/localtime:/etc/localtime:ro - /etc/timezone:/etc/timezone:ro - ./conf:/etc/nginx/conf.d - ./data:/data logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;10m\u0026#34; healthcheck: test: [\u0026#34;CMD-SHELL\u0026#34;, \u0026#34;curl --fail http://127.0.0.1 || exit 1\u0026#34;] interval: 5s networks: traefik: external: true 将静态文件放入 data 目录，对应的nginx配置文件放入 conf 目录。\n这样可以创建Nginx的container，同时labels中定义了nginx的service。\nTraefik Routes 配置示例 这里在traefik的dynamic config新增了routes，没有在labels中定义，因为我想在后续有新的项目需要部署时可以复用这个service。\n1 2 3 4 5 6 7 8 9 10 11 12 13 [http.routers] [http.routers.testroute] entryPoints = [\u0026#34;http\u0026#34;] middlewares = [\u0026#34;https-redirect@file\u0026#34;] rule = \u0026#34;Host(`domain`)\u0026#34; service = \u0026#34;nginxserverhttp\u0026#34; [http.routers.testroutessl] entryPoints = [\u0026#34;https\u0026#34;] middlewares = [\u0026#34;gzip@file\u0026#34;] rule = \u0026#34;Host(`domain`)\u0026#34; service = \u0026#34;nginxserverhttp\u0026#34; [http.routers.testroutessl.tls] certresolver = \u0026#34;le\u0026#34; 结论 Traefik 实现静态文件代理的方式，就是创建静态代理服务器的container，然后配置service和rule，实现静态文件的访问。\n","date":"2021-06-12T02:55:46+08:00","permalink":"https://urzz.xyz/p/traefik-reverse-static-file/","title":"Traefik 静态文件代理"},{"content":" 因为某些原因，重装了两三次PVE和黑群，重装的过程中也碰到一点问题，因此这里记录一下教程。\nPVE的安装这里就不说了，可以参考这个教程：Proxmox VE（PVE）6.1安装保姆级图文教程\n虚拟机配置 VM ID：虚拟机的唯一ID，只要保证跟其他虚拟机的ID不一致即可\n选择不使用任何介质\n如果不需要在DSM中跑Docker，cpu和内存不需要配置太高 这里有一个点需要特别注意，cpu的类别，默认是kvm64。因为host类型才能更好的发挥cpu的性能，所以一开始我改为使用host类型。但是改为host之后，会无法获取DHCP的IP，因此无法配置群晖。所以，PVE安装DSM，CPU类型必须是kvm64。\n网卡类型可以选E1000，虽然性能差点，但是群晖可以直接识别。或者也可以选vmxnet3，但是mac地址需要与群晖引导文件中的mac地址保持一致。\n虚拟机配置列表\n删除默认的scsi0的硬盘以及CD/DVD驱动器\n黑群引导文件配置 黑群晖系统的型号我选择的是3617xs，对应引导文件：地址 提取码: me7h\n将下载的引导文件 synoboot.img 上传到Local存储中 将引导文件作为启动硬盘导入到虚拟机中\n1 2 # 1000: vmid，ssd-c2000pro: 虚拟机存储位置 qm importdisk 1000 /var/lib/vz/template/iso/synoboot.img ssd-c2000pro 双击未使用磁盘，设备设置为SATA:0 另加一块硬盘用于安装系统，不用很大，16G或者32G都行。\n修改选项中的引导顺序，选择SATA0为第一个 接下来启动虚拟机，然后访问：http://find.synology.com/ 即可找到黑群的地址，然后在黑群官方地址: https://archive.synology.com/download/Os/DSM 下载系统pat文件，然后在上面的搜索地址中找到的群晖配置中正常安装系统即可。\n","date":"2021-02-16T02:35:14+08:00","permalink":"https://urzz.xyz/p/pve-install-synology/","title":"PVE 安装黑群晖教程"},{"content":" 海康威视c2000 pro太香了，双十二没忍住剁了个1t的。在此记录一下win10的迁移步骤以及碰到的问题。\n迁移工具选择 AOMEI Backupper 分区助手 其实这俩都可以，因为它们都有一个功能：克隆硬盘。\n克隆硬盘 克隆硬盘首先要保证俩硬盘的分区表是一致的，要么都是mbr，要么都是guid。所以我把ssd装到主机上后，就把硬盘的分区表格式改为了guid。接着并不需要做任何分区的操作，直接打开上面说的两个工具之一，选择克隆硬盘。\n克隆硬盘的时候一定要记住勾选ssd优化，因为ssd我们正常自己用的时候分区也是要设置4k对齐的，这个ssd优化其实就是帮我们做了这一步。\n克隆硬盘完成之后，其实可以把原固态拆下来用新固态启动试试，但是我这一步很自信的直接清了原固态的所有分区和数据，然后我进系统就失败了。\n引导修复 电脑启动会出现：0xc000000e 这样的错误码，同时提示电脑设备需要修复。\n这个错误我查了下说可能是引导丢失引起的，只能想办法修复引导了。如果这个时候手上有个pe系统盘就会很省事了，pe一般都会带bootice这样的引导修复工具，直接打开该工具修复一下引导就行了，具体就不说了。\n但是我手上只有一个win10原版系统的u盘，所以只能靠它来修复引导了。\n设置从系统盘启动 开机启动选择U盘启动就好了，没啥说的\nUEFI引导修复 系统盘里面有个功能叫：修复计算机。点击它进入修复功能，疑难解答-\u0026gt;命令行工具。\n这一步最关键的是你要找到你系统所在分区和efi分区。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 首先进入diskpart工具查询硬盘和分区信息。 \u0026gt; diskpart \u0026gt; list vol # 确定了ESP分区和系统所在分区后，首先给ESP分区分配一个驱动器符，比如G盘 # 如果系统所在分区的驱动器符不是C盘(和以前不一致),也可以在这里修改对应的盘符 # 在确定分区的驱动器符都正确后，首先扫描有哪些系统: \u0026gt; bootrec /scanos # 选择esp分区 \u0026gt; sel vol 1 # 分配盘符 \u0026gt; assign letter=G # 修复引导 \u0026gt; cd /d G:\\EFI\\Microsoft\\Boot\\ # /s S: 指定esp分区所在磁盘 # /f uefi 指定启动方式为uefi，注意之间的空格一定要输入。 # /l zh-cn 指定uefi启动界面语言为简体中文 \u0026gt; bcdboot C:\\windows /s G: /f UEFI\u0026gt; \u0026gt; bcdboot C:\\Windows /l zh-cn /s G: /f ALL # 重建引导的最后一步 \u0026gt; bootrec /rebuildbcd # 退出重启电脑 \u0026gt; exit 退出命令行后，重启电脑，选择硬盘启动就好了。到此uefi的引导修复算是完成了。\n参考 [1] Fix UEFI Boot: Fix for Windows 7, 8, 8.1, 10\n","date":"2019-12-15T18:10:24Z","permalink":"https://urzz.xyz/p/win10-migration-fix-uefi-boot/","title":"Windows10迁移以及UEFI引导修复"},{"content":"介绍 AbstractCollection是Java集合实现类的根抽象实现类，它实现了Collection接口，而集合的三个分支(List,Set,Queue)都是继承这个类然后各自实现扩展：AbstractSet, AbstractList, AbstractQueue。\nAbstractCollection 主要包含了三个分支的常用通用方法，三个分支继承AbstractCollection的各自的抽象类中也有三个分支各自具体实现类会有的一些共用方法，所以每个分支才需要有各自的抽象类。\n源码 JDK version: 1.8.0_202\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 public abstract class AbstractCollection\u0026lt;E\u0026gt; implements Collection\u0026lt;E\u0026gt; { // 独有的构造方法， protected AbstractCollection() { } // 查询相关操作方法 public abstract Iterator\u0026lt;E\u0026gt; iterator(); public abstract int size(); public boolean isEmpty() { return size() == 0; } /** * 判断对象是否在集合中，主要依据对象是否为null来做判断 */ public boolean contains(Object o) { Iterator\u0026lt;E\u0026gt; it = iterator(); if (o==null) { while (it.hasNext()) if (it.next()==null) return true; } else { while (it.hasNext()) if (o.equals(it.next())) return true; } return false; } /** * 返回一个包含该集合所有元素的数组，数组中元素的顺序和集合中的顺序一致。 * 即使在迭代过程中，集合长度被改变，最终也会返回与迭代器长度一致的数组(当集合在迭代期间被其他线程并发修改) * 如果集合中元素比预期的要少，则调用Arrays.copyOf复制数组 * 如果集合中元素比预期的要多，则调用finishToArray生成并返回新的数组 */ public Object[] toArray() { // 这里的数组长度只是调用size()做一个预估，并不代表最终数组长度一定是当前的长度 Object[] r = new Object[size()]; Iterator\u0026lt;E\u0026gt; it = iterator(); for (int i = 0; i \u0026lt; r.length; i++) { // 集合长度少于预期(size())，调用Arrays.copyOf复制数组并返回 if (! it.hasNext()) return Arrays.copyOf(r, i); r[i] = it.next(); } // 判断迭代器是否有剩余的元素没有遍历 // 有的话说明集合长度被增加，调用finishToArray生成新数组并返回 // 没有则说明长度一致，直接返回即可 return it.hasNext() ? finishToArray(r, it) : r; } /** * 返回指定类型的数组 */ @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public \u0026lt;T\u0026gt; T[] toArray(T[] a) { // 这里的数组长度只是调用size()做一个预估，并不代表最终数组长度一定是当前的长度 int size = size(); // 如果传入的数组长度大于等于集合长度，则将当前集合中的元素复制到该传入的数组中 // 如果传入的数组长度小于集合长度，则创建新的数组存储集合中的元素 T[] r = a.length \u0026gt;= size ? a : (T[])java.lang.reflect.Array .newInstance(a.getClass().getComponentType(), size); Iterator\u0026lt;E\u0026gt; it = iterator(); for (int i = 0; i \u0026lt; r.length; i++) { if (! it.hasNext()) { // fewer elements than expected // 集合中的元素个数比预期的要少(被其他线程并发删除元素) if (a == r) { // 如果数组是传入的数组，则将该数组的剩余部分置为null r[i] = null; // null-terminate } else if (a.length \u0026lt; i) { // 如果当前遍历i的数值大于传入数组的长度，则集合元素数量虽然比预期小，但是依旧大于传入数组的长度。 // 直接调用Arrays.copyOf复制并返回新的数组 return Arrays.copyOf(r, i); } else { // 数组是新创建的数组，且当前遍历的i小于等于传入数组的长度。 // 则将新创建数组中的元素复制到传入数组中，若遍历的i小于传入数组长度，将传入数组下标为i的值置为null，返回传入的数组 System.arraycopy(r, 0, a, 0, i); if (a.length \u0026gt; i) { a[i] = null; } } return a; } r[i] = (T)it.next(); } // 集合长度被增加的情况与toArray()最终处理方式一致 return it.hasNext() ? finishToArray(r, it) : r; } /** * 数组扩容的最大值，实际在Java中，数组最大长度限制为 Integer.MAX_VALUE - 2 * 为了防止内存溢出，这里做了限制为 Integer.MAX_VALUE - 8 * 关于为什么最大长度要减去 8: 对于有些虚拟机实现来说，数组对象的头部会占用这 8 个字节，具体细节可参考最后的资料 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * 当在toArray方法中，迭代器返回了比预期要多的元素时，重新扩容数组并将多余预期的元素放入扩容后的数组中 */ @SuppressWarnings(\u0026#34;unchecked\u0026#34;) private static \u0026lt;T\u0026gt; T[] finishToArray(T[] r, Iterator\u0026lt;?\u0026gt; it) { int i = r.length; while (it.hasNext()) { int cap = r.length; // 当索引指向最后一个元素，代表数组长度不够了，需要进行扩容 // 扩容大小：cap + cap/2 + 1 if (i == cap) { int newCap = cap + (cap \u0026gt;\u0026gt; 1) + 1; // 判断扩容后的数组长度是否溢出 if (newCap - MAX_ARRAY_SIZE \u0026gt; 0) newCap = hugeCapacity(cap + 1); r = Arrays.copyOf(r, newCap); } r[i++] = (T)it.next(); } // 如果扩容的容量过多，则只返回实际长度的数组 return (i == r.length) ? r : Arrays.copyOf(r, i); } /** * 判断数组长度是否溢出 */ private static int hugeCapacity(int minCapacity) { // 数组长度溢出，抛出异常 if (minCapacity \u0026lt; 0) throw new OutOfMemoryError (\u0026#34;Required array size too large\u0026#34;); // 判断是否大于数组扩容允许的最大值，若大于则只允许扩容到最大值 return (minCapacity \u0026gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; } // 修改相关操作方法 /** * Collection默认不支持add操作 */ public boolean add(E e) { throw new UnsupportedOperationException(); } /** * 调用迭代器的remove方法删除元素 * 当对应的迭代器没有实现remove方法时，同样会抛UnsupportedOperationException */ public boolean remove(Object o) { Iterator\u0026lt;E\u0026gt; it = iterator(); if (o==null) { while (it.hasNext()) { if (it.next()==null) { it.remove(); return true; } } } else { while (it.hasNext()) { if (o.equals(it.next())) { it.remove(); return true; } } } return false; } // 批量操作方法 /** * 批量判断元素是否都存在 */ public boolean containsAll(Collection\u0026lt;?\u0026gt; c) { for (Object e : c) if (!contains(e)) return false; return true; } /** * 将参数集合中的元素都add到当前集合中 * (若集合未实现add方法，可能会抛UnsupportedOperationException) */ public boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) { boolean modified = false; for (E e : c) if (add(e)) modified = true; return modified; } /** * 批量删除元素 * 通过迭代器，迭代判断集合中是否存在元素，存在就调用remove方法删除元素 */ public boolean removeAll(Collection\u0026lt;?\u0026gt; c) { Objects.requireNonNull(c); boolean modified = false; Iterator\u0026lt;?\u0026gt; it = iterator(); while (it.hasNext()) { if (c.contains(it.next())) { it.remove(); modified = true; } } return modified; } /** * 删除所有不在传入集合中存在的元素 */ public boolean retainAll(Collection\u0026lt;?\u0026gt; c) { Objects.requireNonNull(c); boolean modified = false; Iterator\u0026lt;E\u0026gt; it = iterator(); while (it.hasNext()) { if (!c.contains(it.next())) { it.remove(); modified = true; } } return modified; } /** * 删除集合中的所有元素 */ public void clear() { Iterator\u0026lt;E\u0026gt; it = iterator(); while (it.hasNext()) { it.next(); it.remove(); } } // String conversion /** * 返回集合的字符串表示形式 */ public String toString() { Iterator\u0026lt;E\u0026gt; it = iterator(); if (! it.hasNext()) return \u0026#34;[]\u0026#34;; StringBuilder sb = new StringBuilder(); sb.append(\u0026#39;[\u0026#39;); for (;;) { E e = it.next(); sb.append(e == this ? \u0026#34;(this Collection)\u0026#34; : e); if (! it.hasNext()) return sb.append(\u0026#39;]\u0026#39;).toString(); sb.append(\u0026#39;,\u0026#39;).append(\u0026#39; \u0026#39;); } } } 资料 为什么数组扩容长度限制为 Integer.MAX_VALUE-8 ？ 参考 Why the maximum array size of ArrayList is Integer.MAX_VALUE - 8? ","date":"2019-07-17T16:50:58Z","permalink":"https://urzz.xyz/p/jdk-collection-abstract-collection/","title":"Java 集合源码 - AbstractCollection"},{"content":"定义 什么是单例模式？ 在整个系统中，一个类永远只有一个实例化的对象，被称为单例\n作用 单例模式可以减少一个频繁被创建的重量级对象在多次实例化的时候所花费的时间，当一个类实例化所需要的时间比较长的时候，就可以考虑使用单例了。一来节约了对象多次创建所花费的时间，二来可以节约资源。\n实现 单例模式是最常见、最容易理解、应用最广泛的模式了，其有多重实现方式。但是各个实现方式的优劣都不一样，有挺多的坑。\n饿汉式 1 2 3 4 5 6 7 8 9 10 11 public class Singleton { private static final Singleton INSTANCE = new Singleton(); // Private constructor suppresses // default public constructor private Singleton() {}; public static Singleton getInstance() { return INSTANCE; } } 这种实现是最为简单的单例的实现，因为将INSTANCE对象设为了static final，保证这个对象在类加载的时候就会被实例化，因此它一定是单例的。 当然，这种实现也有缺点，那就是不支持懒加载。无论是否有调用，都会在系统初始化的时候进行实例化，这样在某些场景下是无法使用的，比如该类的实例化依赖参数或者配置文件。\n懒汉式 1 2 3 4 5 6 7 8 9 10 11 public class Singleton { private static Singleton instance; private Singleton (){} public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 懒汉式的实现也比较简单，而且容易理解，并且还支持懒加载。但是这种实现方式有一个重大的缺陷，那就是不支持多线程。 当有多个线程同时调用getInstance方法时，就会实例化多个对象，因此在多线程的情况下，这种实现是不适用的(线程不安全)。\n懒汉式 - 线程安全 为了解决懒汉式不能适用多线程的情况，最简单的方式就是给getInstance加锁，使它变成同步(synchronized)方法。\n1 2 3 4 5 6 7 8 9 10 11 public class Singleton { private static Singleton instance; private Singleton (){} public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 这种实现方式解决了实例化多个对象的问题，做到了线程安全，但是实例化的同步操作应该只有第一次才需要同步，而这个实现使得整个方法变成了同步，导致这个实现存在效率问题。为了解决效率问题，减少同步的开销，就有了下面的双重检验锁的实现方式。\n双重校验锁 维基百科上有对这种模式的解释：双重检查锁定模式 双重检查锁定模式（也被称为\u0026quot;双重检查加锁优化\u0026quot;，\u0026ldquo;锁暗示\u0026rdquo;（Lock hint）[1]) 是一种软件设计模式用来减少并发系统中竞争和同步的开销。双重检查锁定模式首先验证锁定条件(第一次检查)，只有通过锁定条件验证才真正的进行加锁逻辑并再次验证条件(第二次检查)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class Singleton { // 声明成volatile private volatile static Singleton instance; private Singleton (){} public static Singleton getInstance() { // 第一次校验 if (instance == null) { // 第二次加锁校验 synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance ; } } 第一次检查发现还没有实例化的时候，在同步的代码块里面去做实例化。这种方式比较好的实现了线程安全，当多个线程同时调用getInstance方法时，都会判断instance是否为空，然后因为实例化的代码加了锁做了二次校验，因此当线程完成实例化释放锁之后，其他线程在二次校验对象的时候都已经存在了，也就避免了多次实例化的问题。 不过用Java实现双重校验会存在一些问题。实例化的这行代码，它并不是一个原子操作。这行代码大概可以分三步：\n给instance对象分配内存 调用构造器实例化对象 将instance对象指向分配好的内存空间 在JVM中有存在指令重排优化的，所以这行代码的调用顺序可能并不是1-2-3。如果调用顺序是1-3-2，那在实例化对象之前，先将instance指向了分配好的内存空间，就会导致instance在真正被实例化之前，已经是非null的了，那在其他线程调用时，就可能会出现一些错误。 还有，如果在实例化的线程中实例化好了对象，但是由于可见性的原因，另一个线程并不知道这个对象已经被实例化了，那同样也会有多次实例化对象的问题。\n所以，必须将instance对象声明成volatile。\n静态内部类 1 2 3 4 5 6 7 8 9 public class Singleton { private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } private Singleton (){} public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } } 本质上是使用了static final修饰内部类变量，所以只有在类加载的时候才会去实例化对象，除了 getInstance() 之外没有办法访问它，因此可以懒加载。并且只会在类加载的时候实例化一次，天生的线程安全，也没有性能问题。\n枚举 1 2 3 4 5 6 public enum SingletonEnum { INSTANCE; public void anyMethod() { } } 创建枚举默认就是线程安全的，因此不需要一些其他的机制来保证线程安全，可以直接使用SingletonEnum.INSTANCE来访问实例。除此以外，枚举还能防止反序列化导致创建新的对象。\n总结 正确的单例模式的写法大概是以上几种形式（不包括线程不安全的懒汉实现），一般而言其实饿汉式就已经可以满足大多数情况了，如果需要看加载的形式可以使用静态内部类，再进一步需要考虑反序列化的情况，就可以使用枚举了。\n","date":"2019-07-08T20:02:35Z","permalink":"https://urzz.xyz/p/java-singleton-pattern/","title":"设计模式 - 单例模式的几种实现方式"},{"content":" 为了解决跨域请求无法使用cookie的问题，使用nginx对后端服务做了反代。但是反代之后，却发现cookie没有被正确传递。\n相关配置 nginx 反代配置 nginx反代的配置很简单，只是简单设置了proxy_pass\n1 2 3 location /edims-api { proxy_pass http://server_ip:port/; } Spring Boot后端服务配置 后端服务使用内嵌Tomcat，且设置了context-path。\n1 2 3 4 server: # 省略了无关配置 servlet: context-path: /path 分析 打个比方，登录请求需要请求两个接口A和B。在A接口中，会往session中存入一些数据，在访问B接口的时候需要从session中取出A接口存入的数据。在使用了nginx反代了后端服务之后，请求B接口时，无法从session中取到需要的数据，原因在于访问B接口时，浏览器没有自动将cookie带上，所以每次访问接口的session都不一样。\n一般来说，后端在Response Header中设置Set-Cookie之后，浏览器在向服务器发起其他请求时，自动带上设置的cookie，如果没有带上，那就只能说明，肯定是第二次请求接口时，有什么条件不符合导致浏览器没有自动带上cookie。\n参考MDN上的资料（参考 MDN-Cookies）\nThe Domain and Path directives define the scope of the cookie: what URLs the cookies should be sent to.\n浏览器根据cookie的domain和path，决定为哪些url请求发送cookie，而根据我的nginx配置来看，domain肯定是一致的，区别就在于path了。\n首先看一下cookie的path： 再来看一下请求url的path： 原因找到了，因为后端设置的cookie的path与反代之后访问地址的path不一致，才导致浏览器在B接口请求时并没有发送该cookie。\n解决 修改nginx的反代配置，在location中添加proxy_cookie_path\n1 2 3 4 location /edims-api { proxy_pass http://server_ip:port/; proxy_cookie_path /edims-background /edims-api/edims-background; } 总结 一般来说，我们的Java后端应用并不会设置context-path，那默认的cookie的path其实应该是 /，这样的话，也就不会发现反代还会导致cookie丢失这种情况了。不过如果碰到了，只要了解web开发相关的基础知识，也还是很好解决的。\n","date":"2019-07-03T19:08:29Z","permalink":"https://urzz.xyz/p/spring-boot-nginx-cookie-nout-found/","title":"Nginx反代Spring Boot后端服务后，丢失cookie"},{"content":" 最近一个项目的认证是用shiro实现的，以前没有做过spring boot + shiro的整合，所以遇到了一些奇奇怪怪的坑\nshiro的整合具体这边就不做阐述了，大概有以下几个类:\nJwtFilter ShiroConfig JwtRealm JwtToken 这里需要关注的只有前两个类，自定义的filter：JwtFilter，以及Shiro配置类\nShiroConfig.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Bean(\u0026#34;securityManager\u0026#34;) public DefaultWebSecurityManager getManager(@Autowired JwtRealm jwtRealm) { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(jwtRealm); DefaultSubjectDAO subjectDAO = new DefaultSubjectDAO(); DefaultSessionStorageEvaluator defaultSessionStorageEvaluator = new DefaultSessionStorageEvaluator(); defaultSessionStorageEvaluator.setSessionStorageEnabled(false); subjectDAO.setSessionStorageEvaluator(defaultSessionStorageEvaluator); securityManager.setSubjectDAO(subjectDAO); return securityManager; } @Bean(\u0026#34;shiroFilter\u0026#34;) public ShiroFilterFactoryBean factory(DefaultWebSecurityManager securityManager) { ShiroFilterFactoryBean factoryBean = new ShiroFilterFactoryBean(); Map\u0026lt;String, Filter\u0026gt; filterMap = new LinkedHashMap\u0026lt;\u0026gt;(); filterMap.put(SHIRO_JWT_FILTER_NAME, new JwtFilter()); factoryBean.setFilters(filterMap); factoryBean.setSecurityManager(securityManager); Map\u0026lt;String, String\u0026gt; filterRuleMap = new LinkedHashMap\u0026lt;\u0026gt;(); filterRuleMap.put(\u0026#34;/auth/token\u0026#34;, \u0026#34;anon\u0026#34;); filterRuleMap.put(\u0026#34;/v2/api-docs\u0026#34;, \u0026#34;anon\u0026#34;); filterRuleMap.put(\u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;anon\u0026#34;); filterRuleMap.put(\u0026#34;/api/**\u0026#34;, \u0026#34;anon\u0026#34;); filterRuleMap.put(\u0026#34;/**\u0026#34;, SHIRO_JWT_FILTER_NAME); factoryBean.setFilterChainDefinitionMap(filterRuleMap); return factoryBean; } anon失效 因为需要在自定义filter中注入一些属性，所以把JwtFilter交给Spring管理\n1 2 3 4 @Bean public JwtFilter jwtFilter() { return new JwtFilter(); } 同时修改shiroFilter中的filterMap设置\n1 filterMap.put(SHIRO_JWT_FILTER_NAME, jwtFilter()); 但是在修改后，filterChainDefinitionMap中设置为anon的路由规则就失效了，所有的接口请求都会走JwtFilter，而不是先走ShiroFilter。\n原因：\n在将JwtFilter交给Spring管理后，Spring将其注册到filterChain中了，与ShiroFilter同级，所以即使设置了filter的order，在shiroFilter完了之后也会经过JwtFilter，从而导致认证请求调用链的异常\n解决方法：\n不要把JwtFilter交由Spring管理，直接new一个实例，交由ShiroFilterFactoryBean管理。这样可以保证JwtFilter和ShiroFilter的父子关系，保证filter调用链的正确性 但是这样的话，在JwtFilter中就不能进行依赖注入，只能获取applicationContext来获取对应的bean，比较麻烦 依然把JwtFilter交由Spring管理，但是设置这个bean不要注册到filter调用链中 第一个方法只需要把filterMap中JwtFilter获取方式改回new，同时将该类中依赖注入的地方改用获取Spring上下文从而获取bean的方式，这个方式比较麻烦。\n第二个方法则是通过FilterRegistrationBean取消JwtFilter的自动注册，参考 文档\n1 2 3 4 5 6 7 8 @Bean public FilterRegistrationBean registerJwtFilter(@Autowired JwtFilter jwtFilter) { // 设置jwt filter不自动注册到spring管理的监听器中，防止与shiro filter同级，导致该监听器必定执行 FilterRegistrationBean\u0026lt;JwtFilter\u0026gt; jwtFilterRegister = new FilterRegistrationBean\u0026lt;\u0026gt;(jwtFilter); jwtFilterRegister.setEnabled(false); return jwtFilterRegister; } 小结 Spring Boot整合Shiro很方便，但是还是有一些注意点的，甚至有的问题还是与Spring的加载机制有关系\n","date":"2019-06-11T21:33:38Z","permalink":"https://urzz.xyz/p/spring-boot-shiro-custom-filter/","title":"Spring Boot 整合shiro使用自定义filter"},{"content":" 之前的项目都没有跨域的要求，都是通过nginx反代后端接口避免跨域请求的，但是最近的项目要求要处理跨域的请求，所以记录一下\n1. 正常的Spring boot项目 基本的spring boot项目只需要写个配置类，实现WebMvcConfigurer接口的addCorsMappings方法\n1 2 3 4 5 6 7 8 @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026#34;/**\u0026#34;) .allowCredentials(true) .allowedHeaders(\u0026#34;*\u0026#34;) .allowedOrigins(\u0026#34;*\u0026#34;) .allowedMethods(\u0026#34;*\u0026#34;); } 这样就会给所有路由的请求加上跨域所需的headers\n2. Spring Boot + Shiro Spring Boot整合Shiro之后，默认所有请求会先经过shiro的监听器，所以上面的全局方法已经不管用了。（怎么整合shiro就不说了）\n这时候就得祭出第二招，cors监听器。实现一个监听器，放在shiro的监听器之前，这样就可以保证在所有请求到来的时候，都会给response加上跨域headers。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Bean public FilterRegistrationBean corsFilter() { final UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); final CorsConfiguration config = new CorsConfiguration(); // 允许cookies跨域 config.setAllowCredentials(true); // #允许向该服务器提交请求的URI，*表示全部允许，在SpringMVC中，如果设成*，会自动转成当前请求头中的Origin config.addAllowedOrigin(\u0026#34;*\u0026#34;); // #允许访问的头信息,*表示全部 config.addAllowedHeader(\u0026#34;*\u0026#34;); // 预检请求的缓存时间（秒），即在这个时间段里，对于相同的跨域请求不会再预检了 config.setMaxAge(18000L); // 允许提交请求的方法，*表示全部允许 config.addAllowedMethod(\u0026#34;OPTIONS\u0026#34;); config.addAllowedMethod(\u0026#34;HEAD\u0026#34;); config.addAllowedMethod(\u0026#34;GET\u0026#34;); config.addAllowedMethod(\u0026#34;PUT\u0026#34;); config.addAllowedMethod(\u0026#34;POST\u0026#34;); config.addAllowedMethod(\u0026#34;DELETE\u0026#34;); config.addAllowedMethod(\u0026#34;PATCH\u0026#34;); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); FilterRegistrationBean bean = new FilterRegistrationBean(new CorsFilter(source)); // 设置监听器的优先级 bean.setOrder(0); return bean; } 3. 小结 跨域的设置其实很简单，原理就是给response加上跨域的header就完事了\n","date":"2019-06-05T21:13:14Z","permalink":"https://urzz.xyz/p/spring-shiro-cors-config/","title":"Spring Boot 整合shiro后的跨域设置"},{"content":" 之前做的一个对外网关项目，安全需要所以得对参数进行加密校验\n参数 接口交互约定了三个参数：\ntimestamp（请求时间戳） data（实际请求数据，经过加密得到的字符串） sign（以HMAC-SHA1算法对参数的签名） 请求方式 接口统一使用json来进行交互，请求的Content-Type统一为application/json\n方案 1.需引入依赖 commons-codec\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-codec\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-codec\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.根据需要先提供一个工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @UtilityClass @CommonsLog public class EncryptUtils { public static String HMAC_KEY = \u0026#34;abcd1234abcd\u0026#34;; /** * 以HMAC-SHA1算法对字符串toEnc进行签名 */ public static String hmacSha1(String toEnc, String key) { HmacUtils hmacUtils = new HmacUtils(HmacAlgorithms.HMAC_SHA_1, key); return hmacUtils.hmacHex(toEnc); } public static String urlEncode(String str) { return urlEncode(str, StandardCharsets.UTF_8); } public static String urlEncode(String str, Charset charset) { try { return URLEncoder.encode(str, charset.toString()); } catch (UnsupportedEncodingException e) { log.info(\u0026#34;URL encode 失败\u0026#34;, e); return null; } } } 3.声明一个空接口，在下面的参数处理器中，仅处理实现了Encryptable接口的参数类对象\n1 2 public interface Encryptable { } 声明加密后的参数对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Data @NoArgsConstructor @EqualsAndHashCode(callSuper = false) public class EncryptModel { /** * 时间戳(毫秒) */ private Long timestamp; /** * json加密后的字符串 */ private String data; /** * 参数签名 */ private String signature; } 4.通过自定义 RequestBodyAdviceAdapter 来实现对参数的自动解密\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 @RequiredArgsConstructor @ControllerAdvice(assignableTypes = {OpenApiController.class}) @CommonsLog public class RequestDecryptAdvice extends RequestBodyAdviceAdapter { // 请求时间戳检验的时间限制 private static Integer TIME_LIMIT = 5; @Override public boolean supports(MethodParameter methodParameter, Type targetType, Class\u0026lt;? extends HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converterType) { Class\u0026lt;?\u0026gt; clazz = (Class) targetType; return Encryptable.class.isAssignableFrom(clazz); } @Override public HttpInputMessage beforeBodyRead(HttpInputMessage inputMessage, MethodParameter parameter, Type targetType, Class\u0026lt;? extends HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converterType) throws IOException { Class\u0026lt;?\u0026gt; clazz = (Class) targetType; if (Encryptable.class.isAssignableFrom(clazz)) { log.info(\u0026#34;校验OpenApi请求\u0026#34;); ByteArrayInputStream inputStream = convert(inputMessage.getBody()); log.info(\u0026#34;OpenApi请求校验成功\u0026#34;); return new MappingJacksonInputMessage(inputStream, inputMessage.getHeaders()); } else { return super.beforeBodyRead(inputMessage, parameter, targetType, converterType); } } /** * 校验签名 * * @param body 请求体 * @return 转换后的请求参数体 */ private ByteArrayInputStream convert(InputStream body) throws IOException { String content = StreamUtils.copyToString(body, StandardCharsets.UTF_8); EncryptModel encryptModel = JsonUtil.readValue(content, EncryptModel.class); log.info(\u0026#34;OpenApi请求校验, 校验参数: \u0026#34; + JsonUtil.toJson(encryptModel)); checkEncryptModel(encryptModel); Long timestamp = encryptModel.getTimestamp(); log.info(\u0026#34;OpenApi请求校验, 校验时间戳: \u0026#34; + timestamp); checkTimestamp(timestamp); String dataFrom64 = encryptModel.getData(); byte[] data = Base64.decodeBase64(dataFrom64); encryptModel.setData(new String(data)); String rawSign = getRowSign(encryptModel); log.info(\u0026#34;构建参数, 待签名参数：\u0026#34; + rawSign); String sign = EncryptUtils.hmacSha1(rawSign, HMAC_KEY); log.info(\u0026#34;OpenApi请求校验, 校验签名: \u0026#34; + sign); if (StringKit.ne(sign, encryptModel.getSignature())) { throw new OpenApiException(\u0026#34;签名校验失败\u0026#34;); } return new ByteArrayInputStream(data); } /** * 拼接参数，生成待签名的字符串 * @param encryptModel 请求参数 * @return 待签名字符串 */ private String getRowSign(EncryptModel encryptModel) { String data = encryptModel.getData(); JsonNode dataNode = JsonUtil.readValue(data, JsonNode.class); List\u0026lt;String\u0026gt; paramList = new ArrayList\u0026lt;\u0026gt;(); paramList.add(\u0026#34;timestamp=\u0026#34; + EncryptUtils.urlEncode(encryptModel.getTimestamp().toString())); dataNode.fieldNames().forEachRemaining(key -\u0026gt; { String value = dataNode.get(key).asText(null); if (StringUtils.isBlank(value)) { return; } String encode = EncryptUtils.urlEncode(value); paramList.add(key + \u0026#34;=\u0026#34; + encode); }); paramList.sort(String::compareTo); return String.join(\u0026#34;\u0026amp;\u0026#34;, paramList); } /** * 校验加密请求参数 * @param encryptModel 参数 */ private void checkEncryptModel(EncryptModel encryptModel) { if (encryptModel == null) { throw new OpenApiException(\u0026#34;参数不能为空\u0026#34;); } if (encryptModel.getTimestamp() == null) { throw new OpenApiException(\u0026#34;缺少参数: timestamp\u0026#34;); } if (encryptModel.getData() == null) { throw new OpenApiException(\u0026#34;缺少参数: data\u0026#34;); } if (encryptModel.getSignature() == null) { throw new OpenApiException(\u0026#34;缺少参数: signature\u0026#34;); } } /** * 校验请求时间戳 * @param timestamp 时间戳 */ private void checkTimestamp(Long timestamp) { Instant now = Instant.now().atZone(ZoneId.systemDefault()).toInstant(); Instant time = Instant.ofEpochMilli(timestamp).atZone(ZoneId.systemDefault()).toInstant(); if (now.isBefore(time) || now.plus(TIME_LIMIT, ChronoUnit.MINUTES).isBefore(time)) { throw new OpenApiException(\u0026#34;无权访问\u0026#34;); } } } 测试 对接口测试可以通过对controller写单元测试，这是另一部分下次再说。\n小结 如果只是对参数进行参数校验，防止参数被篡改，那其实只需要在收到请求后，对收到的请求参数以同样的方式签名，最终判断签名是否一致，即可防止请求被劫持导致的安全问题。 而Spring对于请求的处理机制，提供了很方便的方式去统一处理请求参数，通过自定义RequestBodyAdvice即可对参数进行统一的解析并校验签名。同样，如果需要对返回值进行统一的加密处理，也可以通过自定义的ResponseBodyAdvice来实现。\n","date":"2019-05-30T14:04:34Z","permalink":"https://urzz.xyz/p/spring-param-encrypt/","title":"基于Spring做请求参数的加解密/签名校验"},{"content":" 服务器新建用户，ssh关闭密码认证，只允许pubkey。但是root可以以pubkey登录，新建的用户却不可以，经检查后发现，pubkey认证对用户目录等相关路径的权限是有要求的。 可在ssh登录命令后加上 -v 参数，查看具体登录日志\n确认ssh key正确添加到~/.ssh/authorized_keys 查看/var/log/secure日志，若是出现 Authentication refused: bad ownership or modes for directory /home/***, 则需要检查用户目录以及~/.ssh等路径的权限 sshd为了安全，对属主的目录和文件权限有所要求。如果权限不对，则ssh的免密码登陆不生效。\n用户目录权限为 755 或者 700，就是不能是77x。 .ssh目录权限一般为755或者700。 authorized_keys权限一般为644 rsa_id权限必须为600 ~ 路径的权限限制： group 和 other 不能有 ~ 路径的写权限： chmod go-w ~ ","date":"2018-12-18T11:57:16Z","permalink":"https://urzz.xyz/p/ssh-pubkey-auth-failed/","title":"SSH 免密码登录失败"},{"content":"今天在公司无意中碰到一个从来没碰到过的空指针异常= =\nJava中，空指针异常应该是最常见的异常了。一般来说，碰到 NullPointerException 直接跳到报错的那一行就很容易就解决了。\n不过有时候空指针异常不是那么容易看出来。\n比如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class NPExceptionDemo { long size; public static Long getSize() { return null; } public static void setSize(long size){ this.size = size; } public static void main(String[] args) { setSize(getSize()); } } 本来我是奇怪，就算传一个null进去也是直接赋值给size啊，怎么会报了空指针呢。。\n然后就javap了一把才发现，Java的自动装箱/拆箱机制具体是怎样的是解决这个异常的关键。\n包装类转换到基本类型，会调用 Long.longValue() ，所以一旦传入的Long是个Null，那肯定会报空指针的！\n事实证明，NullPointerException不会无缘无故出现的。。\n","date":"2017-02-06T22:51:48Z","permalink":"https://urzz.xyz/p/unexpected-java-nullpoint-exception/","title":"印象深刻的Java空指针异常"}]